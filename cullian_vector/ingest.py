#!/usr/bin/env python
"""
data.json'daki kayÄ±tlarÄ±, OpenAIâ€™nin embedding modeliyle vektÃ¶rleÅŸtirip ChromaDB'ye ekler.
"""

import json, os, sys, time
from typing import List
import chromadb
from tqdm import tqdm
import openai
from utils import load_api_key  # resolve_finetuned_model artÄ±k kullanÄ±lmÄ±yor

# -- Parametreler --------------------------------------------------------
DATA_PATH       = "data.json"
COLLECTION_NAME = "cullinan_hotel_facts"
PERSIST_DIR     = "./chroma_db"

# Embedding iÃ§in fine-tune edilmiÅŸ model *kullanÄ±lamaz*; uygun bir baz model seÃ§in
EMBEDDING_MODEL = "text-embedding-3-small"   # dilediÄŸiniz baÅŸka gÃ¶mÃ¼lÃ¼ modelle deÄŸiÅŸtirebilirsiniz

BATCH_SIZE      = 100          # OpenAI Embeddings max 2048 token/toplu
# ------------------------------------------------------------------------


def load_docs(path: str):
    with open(path, "r", encoding="utf-8") as f:
        first = f.readline().strip()
        f.seek(0)
        if first.startswith("{") and first.rstrip().endswith("}"):
            return [json.loads(l) for l in f]
        return json.load(f)


def chunk(lst: List, size: int):
    for i in range(0, len(lst), size):
        yield lst[i : i + size]


def main():
    # 1) API key / model --------------------------------------------------
    openai.api_key = load_api_key()
    model_name = EMBEDDING_MODEL
    print(f"ðŸ§© KullanÄ±lacak embedding modeli: {model_name}")

    # 2) Verileri oku -----------------------------------------------------
    docs = load_docs(DATA_PATH)
    print(f"Toplam {len(docs)} kayÄ±t.")

    # 3) ChromaDB ---------------------------------------------------------
    client = chromadb.PersistentClient(path=PERSIST_DIR)
    collection = client.get_or_create_collection(COLLECTION_NAME)

    # 4) Toplu embedding + insert -----------------------------------------
    for batch in tqdm(list(chunk(docs, BATCH_SIZE)), desc="YÃ¼kleniyor"):
        ids = [d["id"] for d in batch]
        texts = [d["text"] for d in batch]
        metadatas = [d["metadata"] for d in batch]

        # --- OpenAI Embeddings Ã§aÄŸrÄ±sÄ± -----------------------------------
        resp = openai.embeddings.create(
            model=model_name,
            input=texts,
        )
        embeds = [d.embedding for d in resp.data]

        collection.add(
            ids=ids,
            documents=texts,
            metadatas=metadatas,
            embeddings=embeds,
        )
        time.sleep(0.2)  # YumuÅŸak rate-limit iÃ§in

    print(f"âœ… TamamlandÄ± â†’ {PERSIST_DIR}")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        sys.exit(130)