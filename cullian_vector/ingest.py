#!/usr/bin/env python
"""
Cullinan Belek ‚Ä¢ ChromaDB ingestion

‚Ä¢ data.json  ‚ûú  ./chroma_db  ‚ûú  collection: "cullinan_hotel_facts"
‚Ä¢ Eski koleksiyonu siler, tamamƒ±nƒ± yeniden olu≈üturur.
‚Ä¢ OpenAI 2024-03 embedding modellerinden `text-embedding-3-large` kullanƒ±r.
"""

from __future__ import annotations

import json
import sys
from pathlib import Path
from typing import Any, Dict, List

import chromadb                      # pip install chromadb
import openai                        # pip install openai>=1.14
from openai import OpenAI
from tenacity import (
    retry,
    wait_random_exponential,
    stop_after_attempt,
    retry_if_exception_type,
)
from tqdm import tqdm

# ---------------------------------------------------------------------------
# Ortak config mod√ºl√ºnden API anahtarƒ±nƒ± y√ºkle
# ---------------------------------------------------------------------------
sys.path.append("..")                # proje k√∂k√ºn√º mod√ºl arama yoluna ekle
from config import load_api_key      # noqa: E402  (import konumu bilin√ßli)

openai.api_key = load_api_key()      # tek satƒ±rda kimlik doƒürulama

# ---------------------------------------------------------------------------
# Kullanƒ±cƒ±ya g√∂re ayarlanabilir parametreler
# ---------------------------------------------------------------------------
DATA_PATH       = Path("data1_fixed.json")
PERSIST_DIR     = Path("./chroma_db")
COLLECTION_NAME = "cullinan_hotel_facts"
EMBEDDING_MODEL = "text-embedding-3-large"   # gerekirse deƒüi≈ütirilebilir
BATCH_SIZE      = 100                        # max 2048 token / istek
# ---------------------------------------------------------------------------

# ‚îÄ‚îÄ OpenAI istemcisi ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
client = OpenAI()                   # api_key global olarak ≈üimdiden ayarlƒ±

TRANSIENT_ERRORS = (
    openai.RateLimitError,
    openai.APIStatusError,
    openai.APIConnectionError,
    openai.Timeout,
)


@retry(
    wait=wait_random_exponential(min=1, max=60),
    stop=stop_after_attempt(6),
    retry=retry_if_exception_type(TRANSIENT_ERRORS),
)
def embed(texts: List[str]) -> List[List[float]]:
    """Metin listesini embed eder, hata durumunda otomatik yeniden dener."""
    try:
        resp = client.embeddings.create(model=EMBEDDING_MODEL, input=texts)
    except openai.AuthenticationError as exc:
        raise RuntimeError(
            "üö´ OpenAI kimlik doƒürulamasƒ± ba≈üarƒ±sƒ±z. "
            "Ge√ßerli bir anahtar kullandƒ±ƒüƒ±nƒ±zdan emin olun."
        ) from exc
    return [d.embedding for d in resp.data]


def read_dataset(path: Path) -> List[Dict[str, Any]]:
    """Hem JSON array hem de satƒ±r-ba≈üƒ± JSONL formatƒ±nƒ± destekler."""
    with path.open("r", encoding="utf-8") as f:
        first = f.readline().strip()
        f.seek(0)
        if first.startswith("{") and first.endswith("}"):
            return [json.loads(line) for line in f]  # JSONL
        return json.load(f)  # JSON array


def batched(lst: list, size: int):
    """Listeyi sabit b√ºy√ºkl√ºkte yƒ±ƒüƒ±nlara (batch) b√∂ler."""
    for i in range(0, len(lst), size):
        yield lst[i : i + size]


def main() -> None:
    # 1) Veri ----------------------------------------------------------------
    if not DATA_PATH.exists():
        sys.exit(f"‚ùå {DATA_PATH} bulunamadƒ±.")
    docs = read_dataset(DATA_PATH)
    print(f"üìë {len(docs)} kayƒ±t y√ºklendi.")

    # 2) ChromaDB ------------------------------------------------------------
    chroma = chromadb.PersistentClient(path=str(PERSIST_DIR))

    # Mevcut koleksiyonu sil ‚Üí temiz ba≈ülangƒ±√ß
    try:
        chroma.delete_collection(COLLECTION_NAME)
        print(f"üßπ Eski '{COLLECTION_NAME}' koleksiyonu silindi.")
    except (ValueError, KeyError):
        pass  # zaten yoksa

    collection = chroma.get_or_create_collection(COLLECTION_NAME)

    # 3) Embedding + ekleme --------------------------------------------------
    for batch in tqdm(list(batched(docs, BATCH_SIZE)),
                      desc="Embedding & Insert"):
        ids       = [d["chunk_id"]           for d in batch]
        texts     = [d["text_for_embedding"] for d in batch]
        metadatas = [d["metadata"]           for d in batch]

        embeddings = embed(texts)

        collection.add(
            ids=ids,
            documents=texts,
            metadatas=metadatas,
            embeddings=embeddings,
        )

    print(f"‚úÖ Tamamlandƒ± ‚Üí {collection.count()} vekt√∂r kaydedildi.")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        sys.exit(130)