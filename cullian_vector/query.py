#!/usr/bin/env python
"""
CLI:
  Basit arama          â†’  python query.py "Otelin aÃ§Ä±lÄ±ÅŸ tarihi nedir?"
  Ä°lk 8 sonucu ister   â†’  python query.py -k 8 "Ultra Her Åey Dahil ne demek?"
  Arama + yanÄ±t Ã¼ret   â†’  python query.py -a "Odalar deniz manzaralÄ± mÄ±?"
"""

from __future__ import annotations
import argparse, sys
from pathlib import Path

import chromadb                   # pip install chromadb
from openai import OpenAI         # pip install openai>=1.14
from rich import print            # pip install rich

sys.path.append("..")
from config import load_api_key

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ayarlar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PERSIST_DIR     = Path("./chroma_db")
COLLECTION_NAME = "cullinan_hotel_facts"
EMBEDDING_MODEL = "text-embedding-3-large"
ANSWER_MODEL    = "gpt-4o-mini"          # yoksa gpt-3.5-turbo seÃ§in
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def embed_texts(client: OpenAI, texts: list[str]) -> list[list[float]]:
    """Metinleri OpenAI embedding vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    resp = client.embeddings.create(model=EMBEDDING_MODEL, input=texts)
    return [d.embedding for d in resp.data]


def print_hit(rank: int, doc: str, meta: dict, dist: float):
    print(f"[bold cyan][{rank}][/bold cyan] {doc}")
    print(f"    â€¢ cosine: {dist:.3f}")
    print(f"    â€¢ kaynak: {meta.get('source_document', '?')}")
    print(f"    â€¢ konu  : {meta.get('topic', '?')}\n")


def main() -> None:
    parser = argparse.ArgumentParser(description="Cullinan Belek â€¢ VektÃ¶r Arama")
    parser.add_argument("question", nargs="+", help="Sorgu cÃ¼mlesi")
    parser.add_argument("-k", "--top-k", type=int, default=5,
                        help="DÃ¶nen belge sayÄ±sÄ± (vars. 5)")
    parser.add_argument("-a", "--answer", action="store_true",
                        help="Ãœst belgelerden LLM ile yanÄ±t Ã¼ret")
    args = parser.parse_args()

    query = " ".join(args.question).strip()
    if not query:
        parser.error("Sorgu cÃ¼mlesi boÅŸ olamaz.")

    # 1) OpenAI istemcisi
    client = OpenAI(api_key=load_api_key())

    # 2) Sorgu embeddingâ€™i
    query_vec = embed_texts(client, [query])[0]

    # 3) ChromaDB aramasÄ±
    chroma = chromadb.PersistentClient(path=str(PERSIST_DIR))
    col     = chroma.get_collection(COLLECTION_NAME)

    res = col.query(
        query_embeddings=[query_vec],
        n_results=args.top_k,
        include=["documents", "metadatas", "distances"],
    )

    # 4) SonuÃ§larÄ± gÃ¶ster
    print(f"\n[bold yellow]ğŸ” Sorgu:[/bold yellow] {query}\n")
    for rank, (doc, meta, dist) in enumerate(
        zip(res["documents"][0], res["metadatas"][0], res["distances"][0]), 1
    ):
        print_hit(rank, doc, meta, dist)

    # 5) Ä°steÄŸe baÄŸlÄ±: LLM yanÄ±tÄ±
    if args.answer:
        context = "\n".join(
            f"{i+1}. {d}" for i, d in enumerate(res["documents"][0])
        )
        system_msg = (
            "AÅŸaÄŸÄ±da Cullinan Belek oteli hakkÄ±nda bilgi parÃ§alarÄ± var. "
            "KullanÄ±cÄ± sorusuna sadece bu bilgilerden yararlanarak TÃ¼rkÃ§e cevap ver. "
            "Kesin bilgi yoksa 'Bu konuda elimde bilgi yok.' de."
        )
        completion = client.chat.completions.create(
            model=ANSWER_MODEL,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user",
                 "content": f"Bilgiler:\n{context}\n\nSoru: {query}"},
            ],
            temperature=0.2,
        )
        answer = completion.choices[0].message.content.strip()
        print(f"[bold green]\nğŸ’¬ YanÄ±t:[/bold green] {answer}")


if __name__ == "__main__":
    main()
