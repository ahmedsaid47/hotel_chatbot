#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Cullinan Belek â€¢ RAG demo 2.0  (Ä°zlenebilir Hibrit Arama)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Embedding  : OpenAI text-embedding-3-large
- Retriever  : ChromaDB (./chroma_db, collection: cullinan_hotel_facts)
- LLM        : gpt-4o-mini
"""

from __future__ import annotations
import argparse, logging, sys, re, json, textwrap
from pathlib import Path
from typing import Any, Dict, List

import chromadb               # pip install chromadb
from openai import OpenAI      # pip install openai>=1.14
from tenacity import retry, wait_random_exponential, stop_after_attempt
from rich import print, box
from rich.table import Table

sys.path.append("..")
from config import load_api_key  # kendi utilâ€™iniz

# â•­â”€ Genel Ayarlar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
PERSIST_DIR      = Path("./chroma_db")
COLLECTION_NAME  = "cullinan_hotel_facts"
EMBEDDING_MODEL  = "text-embedding-3-large"
LLM_MODEL        = "gpt-4o-mini"
MAX_TOKENS_OUT   = 500

LOG_DIR          = Path("./logs")
LOG_DIR.mkdir(exist_ok=True)
LOG_FILE         = LOG_DIR / "pipeline.log"

# Metadata alan isimlerini tek yerde tutalÄ±m
FIELD_CAP_ADULT  = "maks_kapasite_yetiskin"
FIELD_CAP_CHILD  = "maks_kapasite_cocuk"
FIELD_SWIM_UP    = "swim_up"
FIELD_VIEW       = "manzara"
FIELD_BATHROOMS  = "banyo_sayisi"
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯


# â”€â”€â”€â”€â”€ Loglama (terminal + dosya) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(LOG_FILE, encoding="utf-8")
    ]
)
logger = logging.getLogger("RAGPipeline")


# â”€â”€â”€â”€â”€ Sistem Promptu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = (
    "Sen Cullinan Belek oteli hakkÄ±nda bir uzmansÄ±n. Sana SAÄLANAN NUMARALANDIRILMIÅ KAYNAKLARI kullanarak kullanÄ±cÄ±nÄ±n sorusunu yanÄ±tla. "
    "Kaynaklarda hem doÄŸal dil metinleri hem de yapÄ±sal veriler (kapasite, metrekare, yatak tipleri vb.) bulunabilir. "
    "Ã–zellikle sayÄ±sal veya kesin bilgi istenen sorularda metinden ziyade YAPISAL VERÄ°LERÄ° temel al. "
    "CevabÄ±nda ilgili kaynak numaralarÄ±nÄ± kÃ¶ÅŸeli parantezle belirt (Ã¶rn. [1]). "
    "EÄŸer kaynaklarda cevap yoksa 'Bu konuda bilgim yok.' de."
)


# â”€â”€â”€â”€â”€ YardÄ±mcÄ± Fonksiyonlar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))
def embed_texts(ai: OpenAI, texts: List[str]) -> List[List[float]]:
    resp = ai.embeddings.create(model=EMBEDDING_MODEL, input=texts)
    return [d.embedding for d in resp.data]


class OpenAIEmbeddingFunction(chromadb.EmbeddingFunction):
    def __init__(self, ai_client: OpenAI):
        self._ai = ai_client

    def __call__(self, input: chromadb.Documents) -> chromadb.Embeddings:
        return embed_texts(self._ai, input)


# â”€â”€â”€â”€â”€ Filtre Ã‡Ä±karma â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_filters(question: str) -> Dict[str, Any]:
    """
    Soru -> Chroma 'where' filtresi.
    FarklÄ± senaryolar dÃ¼ÅŸÃ¼nÃ¼lerek OR/AND yapÄ±larÄ± eklenmiÅŸtir.
    """
    q = question.lower()
    clauses: List[Dict[str, Any]] = []

    # YetiÅŸkin kapasitesi (>=)
    if m := re.search(r'(\d+)\s*(kiÅŸilik|yetiÅŸkin)', q):
        num = int(m.group(1))
        clauses.append({
            "$or": [
                {FIELD_CAP_ADULT: {"$gte": num}},         # numerik ise
                {FIELD_CAP_ADULT: str(num)}               # metin ise (eÅŸit)
            ]
        })

    # Swim-up
    if "swim-up" in q or "swim up" in q:
        clauses.append({FIELD_SWIM_UP: True})

    # Manzara
    if "deniz manzaralÄ±" in q:
        clauses.append({FIELD_VIEW: {"$in": ["Deniz", "BahÃ§e + Deniz"]}})
    if "golf manzaralÄ±" in q:
        clauses.append({FIELD_VIEW: "Golf"})

    # Banyo sayÄ±sÄ± (>=)
    if m := re.search(r'(en az|min(?:imum)?)\s*(\d+)\s*banyo', q):
        num = int(m.group(2))
        clauses.append({FIELD_BATHROOMS: {"$gte": num}})

    if not clauses:
        return {}
    return {"$and": clauses} if len(clauses) > 1 else clauses[0]


# â”€â”€â”€â”€â”€ BaÄŸlam BirleÅŸtirme â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_context(docs: List[str], metas: List[dict]) -> str:
    parts = []
    for idx, (doc, meta) in enumerate(zip(docs, metas), 1):
        oda = meta.get("oda_tipi", "Genel Bilgi")
        cap_a = meta.get(FIELD_CAP_ADULT)
        cap_c = meta.get(FIELD_CAP_CHILD, 0)
        cap_txt = f"{cap_a} yetiÅŸkin" if cap_a is not None else "Kapasite belirsiz"
        if cap_c:
            cap_txt += f" + {cap_c} Ã§ocuk"

        yatak_txt = ""
        if (raw := meta.get("yatak_opsiyonlari_json")):
            try:
                j = json.loads(raw)
                yatak_txt = " / ".join(
                    f"{opt['opsiyon_adi']}: " +
                    ", ".join(f"{y['adet']}Ã—{y['boyut']}" for y in opt["yataklar"])
                    for opt in j
                )
            except Exception:
                yatak_txt = "Yatak detayÄ± okunamadÄ±"

        ctx = (
            f"[{idx}] Oda Tipi: {oda} | Kapasite: {cap_txt}\n"
            f"    Metin: {doc}\n"
            f"    Yataklar: {yatak_txt}\n"
            f"    (Kaynak: {meta.get('source_document', '?')})"
        )
        parts.append(ctx)
    return "\n\n".join(parts)


# â”€â”€â”€â”€â”€ Ana Ã‡alÄ±ÅŸma â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main() -> None:
    ap = argparse.ArgumentParser(
        description="Cullinan Belek â€¢ RAG Pipeline 2.0",
        formatter_class=argparse.RawTextHelpFormatter)
    ap.add_argument("question", nargs="+", help="KullanÄ±cÄ± sorusu")
    ap.add_argument("-k", "--top-k", type=int, default=4, help="DÃ¶nÃ¼ÅŸ adedi (vars: 4)")
    ap.add_argument("-T", "--temperature", type=float, default=0.1, help="LLM sÄ±caklÄ±ÄŸÄ±")
    ap.add_argument("--inspect", action="store_true",
                    help="Koleksiyondan Ã¶rnek meta alanlarÄ±nÄ± yazdÄ±r ve Ã§Ä±k")
    args = ap.parse_args()

    q_text = " ".join(args.question).strip()

    # â”€â”€ OpenAI baÄŸlantÄ±sÄ±
    try:
        ai = OpenAI(api_key=load_api_key())
    except Exception as e:
        logger.error("API anahtarÄ± yÃ¼klenemedi: %s", e)
        sys.exit(1)

    # â”€â”€ Chroma baÄŸlantÄ±sÄ±
    chroma = chromadb.PersistentClient(path=str(PERSIST_DIR))
    col = chroma.get_collection(
        name=COLLECTION_NAME,
        embedding_function=OpenAIEmbeddingFunction(ai)
    )

    if args.inspect:
        sample = col.get(limit=3, include=["metadatas"])
        table = Table(title="Ã–rnek Metadata", box=box.SIMPLE, show_edge=False)
        for i, meta in enumerate(sample["metadatas"], 1):
            table.add_row(f"[{i}]", json.dumps(meta, ensure_ascii=False, indent=2))
        print(table)
        sys.exit(0)

    # â”€â”€ Filtre Ã§Ä±kar + logla
    where = extract_filters(q_text)
    logger.info("Filtre: %s", where or "Yok")

    # â”€â”€ Sorgu 1: filtreli
    res = col.query(query_texts=[q_text], n_results=args.top_k,
                    where=where, include=["documents", "metadatas"])

    # Geri dÃ¶nÃ¼ÅŸ yoksa filtresiz dene
    if not res["documents"][0]:
        logger.warning("Filtreli sorguda sonuÃ§ yok, filtresiz deniyorumâ€¦")
        res = col.query(query_texts=[q_text], n_results=args.top_k,
                        include=["documents", "metadatas"])
        if not res["documents"][0]:
            print("[bold red]HiÃ§ sonuÃ§ bulunamadÄ±.[/bold red]")
            sys.exit(0)

    docs, metas = res["documents"][0], res["metadatas"][0]
    context = build_context(docs, metas)

    # â”€â”€ LLM Ã§aÄŸrÄ±sÄ±
    msgs = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user",
         "content": f"Soru: {q_text}\n\n--- KAYNAKLAR ---\n{context}\n\nCevabÄ±n:"}
    ]
    reply = ai.chat.completions.create(
        model=LLM_MODEL,
        messages=msgs,
        temperature=args.temperature,
        max_tokens=MAX_TOKENS_OUT
    ).choices[0].message.content

    # â”€â”€ Ã‡Ä±ktÄ±lar
    print(f"\n[bold yellow]â“ Soru:[/bold yellow] {q_text}\n")
    print("[bold cyan]ğŸ” Kaynaklar:[/bold cyan]")
    for i, m in enumerate(metas, 1):
        print(f"  [{i}] {m.get('oda_tipi', 'Bilinmeyen')}  "
              f"(Kaynak: {m.get('source_document', '?')})")
    print("\n[bold green]ğŸ’¬ YanÄ±t:[/bold green]\n")
    print(textwrap.fill(reply, width=100))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        sys.exit(130)
    except Exception as exc:
        logger.exception("Beklenmedik hata: %s", exc)
        sys.exit(1)
